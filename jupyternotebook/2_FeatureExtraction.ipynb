{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import sed_eval\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PNCC(y,sr,parameters):\n",
    "    '''\n",
    "    Calculate the\n",
    "        MFCCs : Mel-frequency cepstral coefficients (MFCCs)\n",
    "        PCENs : using PCEN() to replace the log amplitude (dB) scaling on Mel spectra\n",
    "    '''\n",
    "    win_size = parameters['win_size']\n",
    "    hop_size = parameters['hop_size']\n",
    "    n_mels = parameters['num_mel_filters']\n",
    "    n_dct = parameters['n_dct']\n",
    "    fmin = parameters['min_freq']\n",
    "    fmax = parameters['max_freq']\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, \n",
    "                                                    sr=sr,\n",
    "                                                    n_fft=win_size, \n",
    "                                                    hop_length=hop_size, \n",
    "                                                    power=1, \n",
    "                                                    n_mels= n_mels)\n",
    "    \n",
    "    #S_PNCC = librosa.pcen(mel_spectrogram * (2**31))#see detail in librosa doc for why scaling here\n",
    "    S_PNCC = librosa.pcen(mel_spectrogram * (2**31), gain=0.8, bias=10,\n",
    "                               power=0.25, time_constant=0.06)\n",
    "    return scipy.fftpack.dct(S_PNCC, axis=0, type=2, norm='ortho')[:n_dct]\n",
    "#================================================================================================\n",
    "def FeatureExtraction(FilePath,Parameters):\n",
    "    sr = Parameters['sampling_rate']\n",
    "    win_size =  Parameters['win_size']\n",
    "    hop_size = Parameters['hop_size']\n",
    "\n",
    "    audio_data,audio_sr = librosa.load(FilePath,sr, mono = True)\n",
    "\n",
    "    #Other Features might be used========================================================\n",
    "    #audio_mag = np.abs(librosa.stft(audio_data, n_fft=win_size, hop_length=hop_size)) \n",
    "    #Short Time Energy\n",
    "    #ste = ShortTimeEnergy(signal=audio_data,win_size=win_size,hop_size=hop_size)\n",
    "        #ZCR\n",
    "    #zcr = librosa.feature.zero_crossing_rate(y=audio_data,frame_length=win_size,hop_length=hop_size)\n",
    "        #Spectral Centroid\n",
    "    #cent = librosa.feature.spectral_centroid(y=audio_data, sr=sr,n_fft=win_size, hop_length=hop_size)\n",
    "        #Spectral Entropy\n",
    "    #entropy = Spectral_Entropy(y_Mag=audio_mag,sr=sr,n_short_blocks=10)\n",
    "        #MFCCs and MFCCs with PCEN scaling\n",
    "    #mfccs, pcens = PCEN_MFCC(y=audio_data,sr=sr,parameters=Parameters)\n",
    "    #mfccs = librosa.feature.mfcc(y=audio_data, n_fft=win_size, hop_length=hop_size, sr=sr, n_mfcc=20, dct_type=2, norm='ortho')\n",
    "    pnccs = PNCC(y=audio_data, sr=sr, parameters = Parameters)\n",
    "    #Flatten all the feature matrix and concatenate them into a 1D vector\n",
    "    #feature_vector = np.concatenate((mfccs,pnccs), axis = 0)\n",
    "    return pnccs, audio_data, audio_sr\n",
    "#================================================================================================\n",
    "def CreateLabelVector(Data,EventList,Parameters,LabelIndex=1):\n",
    "    #Given audio data, event list, create its corresponding label vector with given index\n",
    "    #list for saving number of frame labels. \n",
    "    hop_size = Parameters['hop_size']\n",
    "    audio_sr = Parameters['sampling_rate']\n",
    "    label_vector = np.zeros(int(np.ceil(len(Data)/hop_size)))                      \n",
    "    for event in EventList:\n",
    "        osnet_frame = np.ceil(event['onset'] * audio_sr/hop_size).astype(int)\n",
    "        offset_frame = np.floor(event['offset'] * audio_sr/hop_size).astype(int)\n",
    "        label_vector[osnet_frame:offset_frame] = LabelIndex\n",
    "    return label_vector.astype(int)\n",
    "\n",
    "def ComputeStateTransition(LabelVector):\n",
    "        #Calculate the probability of status transition If data contains speech \n",
    "        ee_temp = 0 # num of event to event\n",
    "        nn_temp = 0 # num of none to none\n",
    "        en_temp = 0 # num of event to none\n",
    "        ne_temp = 0 # num of none to event\n",
    "        previous_e = 0 # num of frames with previous is event\n",
    "        previous_n = 0 # num of frames with previous is none\n",
    "        if sum(LabelVector) != 0:\n",
    "            for frame_index in range(len(LabelVector)-1):\n",
    "                if LabelVector[frame_index] == 0 and LabelVector[frame_index+1] > LabelVector[frame_index]:\n",
    "                    previous_n = previous_n + 1\n",
    "                    ne_temp = ne_temp + 1\n",
    "                elif LabelVector[frame_index] == 0 and LabelVector[frame_index+1] == LabelVector[frame_index]:\n",
    "                    previous_n = previous_n + 1\n",
    "                    nn_temp = nn_temp + 1\n",
    "                elif LabelVector[frame_index] == 1 and LabelVector[frame_index+1] < LabelVector[frame_index]:\n",
    "                    previous_e = previous_e + 1\n",
    "                    en_temp = en_temp + 1\n",
    "                elif LabelVector[frame_index] == 1 and LabelVector[frame_index+1] == LabelVector[frame_index]:\n",
    "                    previous_e = previous_e + 1\n",
    "                    ee_temp = ee_temp + 1\n",
    "            #compute the probability        \n",
    "            p_ee = ee_temp/previous_e\n",
    "            p_nn = nn_temp/previous_n\n",
    "            p_en = en_temp/previous_e\n",
    "            p_ne = ne_temp/previous_n\n",
    "        return p_ee,p_nn,p_en,p_ne\n",
    "#=================================================================================================================\n",
    "def CreateDataset(Files_Dir,Parameters,Property,EventLabel='speech'):\n",
    "    #Process all the .wav, .txt, in the assigned folder\n",
    "    \n",
    "    #Files_Dir: Target folder for saving all raw audio data\n",
    "    #Parameters: Using  for processing audio files\n",
    "    #Property:Create train/test set?\n",
    "    #EventLabel: The label in string which indicate the class you want to learn\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    #Calculate the Transition Matrix From Training set,saving the probability of each status transition\n",
    "    SS = []#Speech to Speech\n",
    "    NN = []#NonSpeech to NonSpeech\n",
    "    SN = []#Speech to NonSpeech\n",
    "    NS = []#NonSpeech to Speech\n",
    "    \n",
    "    file_index = 1\n",
    "    group = []\n",
    "    for root, dirs,files in os.walk(Files_Dir):\n",
    "        #.txt-based: which means processing txt first then find its corresponding .wav file\n",
    "        \n",
    "        #root_path,subfolders = root,dirs\n",
    "        for file in os.listdir(root):   \n",
    "            if file.endswith('.txt'):  \n",
    "                print('Processing file.{} for {} set'.format(file_index,Property))\n",
    "                file_path = root + '/' + file\n",
    "                processed_filename =  os.path.splitext(file)[0]\n",
    "                #Load Annotated Information\n",
    "                annotated_event = sed_eval.io.load_event_list(file_path)\n",
    "                target_event = sed_eval.util.event_list.filter_event_list(annotated_event, scene_label=None, event_label=EventLabel, filename=None)\n",
    "\n",
    "                #Load Audio for feature extraction\n",
    "                audio_file_name = os.path.splitext(file)[0] + '.wav'\n",
    "                audio_file_path = root + '/' + audio_file_name             \n",
    "                feature_vector,audio_data, audio_sr = FeatureExtraction(audio_file_path,Parameters)\n",
    "\n",
    "                #Using Annotation info to create the vector labels\n",
    "                label_vector = CreateLabelVector(Data=audio_data,\n",
    "                                                     EventList=target_event,\n",
    "                                                     Parameters=Parameters,\n",
    "                                                     LabelIndex=1)    \n",
    "                if feature_vector.shape[1] != len(label_vector):\n",
    "                    print('===========Waring! Unmatched data size,will skip this file:==========')\n",
    "                    print(file_path)\n",
    "                    continue\n",
    "\n",
    "                #Calculate the probability in the transition state matrix If data contains speech \n",
    "                if sum(label_vector) != 0:\n",
    "                    #probability of ss,nn,sn,ns; n=nonspeech, s = speech\n",
    "                    p_ss, p_nn, p_sn, p_ns = ComputeStateTransition(label_vector)                \n",
    "                    SS.append(p_ss)\n",
    "                    NN.append(p_nn)\n",
    "                    SN.append(p_sn)\n",
    "                    NS.append(p_ns)\n",
    "                #create group list\n",
    "                temp_group = np.ones(len(label_vector))*file_index\n",
    "                group = group + temp_group.astype(int).tolist()\n",
    "                \n",
    "                data.append([feature_vector,label_vector])\n",
    "                file_index += 1\n",
    "    \n",
    "    #Transition Matrix:\n",
    "    trans_matrix = np.array([[np.mean(SS),1 - np.mean(SS)],[1 - np.mean(NN),np.mean(NN)]])\n",
    "    #Saving the transition Matrix\n",
    "    np.save(os.getcwd()+'/JPNotebookExported/' + Property + '_TransitionMatrix.npy', trans_matrix)\n",
    "    np.save(os.getcwd()+'/JPNotebookExported/' + Property + '_Dataset.npy', np.asarray(data))\n",
    "    #Saving group info\n",
    "    np.save(os.getcwd()+'/JPNotebookExported/' + Property + '_GroupK.npy', np.asarray(group))\n",
    "    print(trans_matrix)\n",
    "    \n",
    "    return np.asarray(data),trans_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file.1 for Example_Audio set\n",
      "[[0.98717949 0.01282051]\n",
      " [0.00284091 0.99715909]]\n",
      "Generating all dataset took 0.014804502328236898 mins.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "Params = {\n",
    "        'sampling_rate':22050,\n",
    "        'win_size': 1024,\n",
    "        'hop_size': 512,\n",
    "        'min_freq': 80,\n",
    "        'max_freq': 8000,\n",
    "        'num_mel_filters': 128,\n",
    "        'n_dct': 20}\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "#Train\n",
    "Train_path = os.getcwd() + '/1_Dataset_Generate/audio/soundbanks/perturbations/IRConvolution/'\n",
    "TrainData,TrainTransMatrix = CreateDataset(Files_Dir = Train_path,\n",
    "                                                          Parameters = Params,\n",
    "                                                          Property = 'Deformed_PTDCI_PCEN_lostanlen')\n",
    "\n",
    "#Validate\n",
    "Validate_path = os.getcwd() + '/1_Dataset_Generate/audio/soundbanks/Validate/generated'\n",
    "ValidateData,ValidateTransMatrix = CreateDataset(Files_Dir = Validate_path,\n",
    "                                                                   Parameters = Params,\n",
    "                                                                   Property = 'Validation_PCEN_lostanlen')\n",
    "\n",
    "\n",
    "#Test\n",
    "Test_path = os.getcwd() + '/1_Dataset_Generate/audio/soundbanks/Test/generated'\n",
    "TestData,TestTransMatrix = CreateDataset(Files_Dir = Test_path,\n",
    "                                                       Parameters = Params,\n",
    "                                                     Property = 'Test_PCEN_P')\n",
    "                                                     \n",
    "              \n",
    "print(\"Generating all dataset took {} mins.\" .format((time() - start_time)/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
